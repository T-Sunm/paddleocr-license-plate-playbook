{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9219844d",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82732cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu xử lý 10 file...\n",
      "Xử lý xong! Kết quả đã được lưu tại: /home/temp-user/workspace/plate-recognition-low-resolution/agency_contacts.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Cấu hình ---\n",
    "DATA_DIR = \"/home/temp-user/workspace/plate-recognition-low-resolution/out/agencyvietnam\"\n",
    "OUT_FILE = \"/home/temp-user/workspace/plate-recognition-low-resolution/agency_contacts.txt\"\n",
    "\n",
    "# Regrex theo yêu cầu (Lưu ý: bỏ dấu $ ở cuối email để findall tìm được trong văn bản)\n",
    "email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "phone_pattern = r\"(?:\\+84|84|0)(?:\\s|\\.|\\-|\\(|\\))?(?:\\d(?:\\s|\\.|\\-|\\(|\\))?){9,11}\"\n",
    "\n",
    "def decode_cf_email(encoded_str):\n",
    "    \"\"\"Giải mã email bị Cloudflare obfuscate\"\"\"\n",
    "    r = int(encoded_str[:2], 16)\n",
    "    return \"\".join([chr(int(encoded_str[i:i+2], 16) ^ r) for i in range(2, len(encoded_str), 2)])\n",
    "\n",
    "results = []\n",
    "\n",
    "# Duyệt qua các file HTML đã tải về\n",
    "files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".html\") and f != \"index.html\"]\n",
    "files.sort()\n",
    "\n",
    "print(f\"Bắt đầu xử lý {len(files)} file...\")\n",
    "\n",
    "for filename in files:\n",
    "    file_path = os.path.join(DATA_DIR, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    # 1. Lấy tên Agency (thẻ h1)\n",
    "    name_el = soup.select_one(\"h1.display-5\")\n",
    "    name = name_el.get_text(strip=True) if name_el else \"Unknown\"\n",
    "    \n",
    "    # 2. Tìm danh sách Email\n",
    "    emails = set(re.findall(email_pattern, html_content, re.IGNORECASE))\n",
    "    # Giải mã thêm các email từ Cloudflare (nếu có)\n",
    "    for cf in soup.select(\"[data-cfemail]\"):\n",
    "        try:\n",
    "            emails.add(decode_cf_email(cf[\"data-cfemail\"]))\n",
    "        except: continue\n",
    "        \n",
    "    # 3. Tìm danh sách Số điện thoại\n",
    "    phones = set(re.findall(phone_pattern, html_content))\n",
    "    \n",
    "    results.append({\n",
    "        \"name\": name,\n",
    "        \"emails\": sorted(list(emails)),\n",
    "        \"phones\": sorted(list(phones)),\n",
    "        \"file\": filename\n",
    "    })\n",
    "\n",
    "# --- Lưu kết quả vào file ---\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    for res in results:\n",
    "        f.write(f\"Agency: {res['name']}\\n\")\n",
    "        f.write(f\"File: {res['file']}\\n\")\n",
    "        f.write(f\"Emails: {', '.join(res['emails']) if res['emails'] else 'N/A'}\\n\")\n",
    "        f.write(f\"Phones: {', '.join(res['phones']) if res['phones'] else 'N/A'}\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "print(f\"Xử lý xong! Kết quả đã được lưu tại: {OUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954dc370",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b89391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Articles: 100%|██████████| 100/100 [06:33<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xử lý hoàn tất!\n",
      "- Kết quả lưu tại thư mục: /home/temp-user/workspace/plate-recognition-low-resolution/out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from underthesea import word_tokenize, ner, classify\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Cấu hình ---\n",
    "DATA_DIR = \"/home/temp-user/workspace/plate-recognition-low-resolution/out/travel\"\n",
    "LOCATIONS = {\n",
    "    \"hanoi\": [\"Hà Nội\", \"Thủ đô\", \"Hoàn Kiếm\", \"Ba Đình\"],\n",
    "    \"danang\": [\"Đà Nẵng\", \"Sông Hàn\", \"Ngũ Hành Sơn\"],\n",
    "    \"quangbinh\": [\"Quảng Bình\", \"Sơn Đoòng\", \"Phong Nha\", \"Đồng Hới\"]\n",
    "}\n",
    "\n",
    "# Khởi tạo kết quả\n",
    "category_map = {} # Phân loại theo category\n",
    "location_files = {loc: [] for loc in LOCATIONS} # Phân loại theo địa điểm\n",
    "\n",
    "# Lấy danh sách file bài viết\n",
    "files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".txt\") and f != \"urls.txt\"]\n",
    "files.sort()\n",
    "\n",
    "# Sử dụng tqdm để theo dõi tiến độ\n",
    "for filename in tqdm(files, desc=\"Processing Articles\"):\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) < 3: continue\n",
    "        \n",
    "        title = lines[0].strip()\n",
    "        url = lines[2].strip()\n",
    "        body = \"\".join(lines[4:]).strip()\n",
    "        full_text = title + \" \" + body\n",
    "\n",
    "    # 1. Word Tokenize (từ ghép nối bởi _) và NER\n",
    "    tokenized_text = word_tokenize(full_text, format=\"fixed\")\n",
    "    entities = ner(full_text)\n",
    "    \n",
    "    # 2. Phân loại bài viết (Classify)\n",
    "    try:\n",
    "        cat = classify(full_text)\n",
    "        cat_name = cat[0] if cat else \"Khác\"\n",
    "    except: cat_name = \"Khác\"\n",
    "    \n",
    "    if cat_name not in category_map: category_map[cat_name] = []\n",
    "    category_map[cat_name].append(f\"{title} - {url}\")\n",
    "\n",
    "    # 3. Lọc theo từ khóa địa điểm\n",
    "    for loc_key, keywords in LOCATIONS.items():\n",
    "        if any(kw.lower() in full_text.lower() for kw in keywords):\n",
    "            location_files[loc_key].append(f\"{title}\\n{url}\\n\")\n",
    "\n",
    "# --- Lưu kết quả ---\n",
    "# Lưu file địa điểm\n",
    "for loc, content in location_files.items():\n",
    "    if content:\n",
    "        out_path = os.path.join(os.path.dirname(DATA_DIR), f\"{loc}.txt\")\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(content))\n",
    "\n",
    "# Lưu file phân loại category\n",
    "summary_path = os.path.join(os.path.dirname(DATA_DIR), \"categories_summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for cat, articles in category_map.items():\n",
    "        f.write(f\"=== DANH MỤC: {cat.upper()} ===\\n\")\n",
    "        f.write(\"\\n\".join(articles) + \"\\n\\n\")\n",
    "\n",
    "print(\"\\nXử lý hoàn tất!\")\n",
    "print(f\"- Kết quả lưu tại thư mục: {os.path.dirname(DATA_DIR)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
